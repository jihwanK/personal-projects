{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import dgl\n",
    "from dgl.nn import GATv2Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HOME = \"/lyceum/jhk1c21/msc_project/data\"\n",
    "V14_PATH = os.path.join(DATA_HOME, \"graph\", \"v14\")\n",
    "FILTERED_PATH = os.path.join(V14_PATH, \"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "nodes = pd.read_csv(os.path.join(V14_PATH, \"nodes_v14.csv\"), index_col='id')\n",
    "similarity = pd.read_csv(os.path.join(FILTERED_PATH, \"similarity_edges.csv\"))\n",
    "\n",
    "titles = np.load(os.path.join(FILTERED_PATH, 'title_embedding.npy'))\n",
    "abstracts = np.load(os.path.join(FILTERED_PATH, 'abstract_embedding.npy'))\n",
    "keywords = np.load(os.path.join(FILTERED_PATH, 'keywords_embedding.npy'))\n",
    "domains = np.load(os.path.join(FILTERED_PATH, 'domains_embedding.npy'))\n",
    "\n",
    "ids = np.load(os.path.join(FILTERED_PATH, \"filtered_id.npy\"))\n",
    "edges = np.load(os.path.join(FILTERED_PATH, 'filtered_edge.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['src'] = edges[:, 0]\n",
    "df['dst'] = edges[:, 1]\n",
    "\n",
    "# convert id from str to numbers\n",
    "id_to_int = {original_id: i for i, original_id in enumerate(ids)}\n",
    "int_to_id = {i: original_id for original_id, i in id_to_int.items()}\n",
    "\n",
    "df['src'] = df['src'].apply(lambda x: id_to_int[x])\n",
    "df['dst'] = df['dst'].apply(lambda x: id_to_int[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_title = torch.FloatTensor(titles)\n",
    "tensor_abstract = torch.FloatTensor(abstracts)\n",
    "tensor_keywords = torch.FloatTensor(keywords)\n",
    "tensor_domain = torch.FloatTensor(domains)\n",
    "\n",
    "node_features = np.concatenate([titles, abstracts, keywords, domains], axis=1)\n",
    "tensor_node_features = torch.FloatTensor(node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_network = dgl.graph( (df['src'], df['dst']) )\n",
    "citation_network.ndata['features'] = tensor_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(pair, linked_pair, features):\n",
    "    w1, w2, w3, w4, w5 = 0.25, 0.2, 0.2, 0.35, 0.1\n",
    "    \n",
    "    titles, abstracts, keywords, domains = features[:, :300], features[:, 300:600], features[:, 600:900], features[:, 900:1200]\n",
    "    titles_similarity = F.cosine_similarity(titles[pair[:,0]], titles[pair[:,1]])\n",
    "    abstracts_similarity = F.cosine_similarity(abstracts[pair[:,0]], abstracts[pair[:,1]])\n",
    "    keywords_similarity = F.cosine_similarity(keywords[pair[:,0]], keywords[pair[:,1]])\n",
    "    domains_dissimilarity = 1 - F.cosine_similarity(domains[pair[:,0]], domains[pair[:,1]])\n",
    "    \n",
    "    if linked_pair.shape[0] == 0:\n",
    "        weighted_link_similarity = torch.zeros((pair.shape[0],), dtype=torch.float32)\n",
    "    else:\n",
    "        overlap_mask = (linked_pair[:, None, :] == pair[None, :, :]).all(dim=2)\n",
    "        overlap_mask_1d = overlap_mask.any(dim=0)\n",
    "        weighted_link_similarity = overlap_mask_1d.float()\n",
    "\n",
    "    return w1*titles_similarity + w2*abstracts_similarity + w3*keywords_similarity + w4*domains_dissimilarity + w5*weighted_link_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_positive_negative_pairs(graph, node_features, high_threshold = 0.6, low_threshold = 0.4, n_samples=10_000):\n",
    "\n",
    "    n_nodes = graph.number_of_nodes()\n",
    "    random_pair = torch.randint(0, n_nodes, (n_samples, 2))\n",
    "\n",
    "    src = random_pair[:, 0].numpy()\n",
    "    dst = random_pair[:, 1].numpy()\n",
    "\n",
    "    dfs = df.set_index(['src', 'dst'])\n",
    "    linked_random_pair = dfs[dfs.index.isin(list(zip(src, dst)))].reset_index()[['src', 'dst']].to_numpy()\n",
    "    linked_random_pair = torch.FloatTensor(linked_random_pair)\n",
    "    \n",
    "    scores = similarity_score(random_pair, linked_random_pair, node_features)\n",
    "    positive_pairs = random_pair[scores > high_threshold]\n",
    "    negative_pairs = random_pair[scores < low_threshold]\n",
    "    \n",
    "    return positive_pairs, negative_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.layer1 = GATv2Conv(in_dim, hidden_dim, num_heads=num_heads, allow_zero_in_degree=True)\n",
    "        self.layer2 = GATv2Conv(hidden_dim * num_heads, out_dim, num_heads=1, allow_zero_in_degree=True)\n",
    "\n",
    "    def forward(self, graph, features):\n",
    "        # h = self.layer1(graph, features).view(h.size(0), -1)\n",
    "        h = self.layer1(graph, features).flatten(1)\n",
    "        h = F.elu(h)\n",
    "        h = self.layer2(graph, h).squeeze(1)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    # as output dimension is different\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAT(in_dim=1200, hidden_dim=100, out_dim=50, num_heads=4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([162207, 50])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'msc (Python 3.10.12)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # Adjust the number of epochs\n",
    "    model.train() # train starts\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    criterion = ContrastiveLoss()\n",
    "    \n",
    "    output = model(citation_network, citation_network.ndata['features'])\n",
    "    positive_pairs, negative_pairs = generate_positive_negative_pairs(citation_network, tensor_node_features, n_samples=10000)\n",
    "    \n",
    "    loss = 0\n",
    "    for pair in positive_pairs:\n",
    "        output1, output2 = output[pair[0]], output[pair[1]]\n",
    "        label = torch.Tensor([0])\n",
    "        loss += criterion(output1.unsqueeze(0), output2.unsqueeze(0), label)\n",
    "    \n",
    "    for pair in negative_pairs:\n",
    "        output1, output2 = output[pair[0]], output[pair[1]]\n",
    "        label = torch.Tensor([1])\n",
    "        loss += criterion(output1.unsqueeze(0), output2.unsqueeze(0), label)\n",
    "    \n",
    "    loss /= (len(positive_pairs) + len(negative_pairs))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/100], Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000]) torch.Size([10000]) torch.Size([10000]) torch.Size([10000]) torch.Size([10000])\n",
      "torch.Size([10000]) torch.Size([10000]) torch.Size([10000]) torch.Size([10000]) torch.Size([10000])\n",
      "torch.Size([10000]) torch.Size([10000]) torch.Size([10000]) torch.Size([10000]) torch.Size([10000])\n",
      "torch.Size([10000]) torch.Size([10000]) torch.Size([10000]) torch.Size([10000]) torch.Size([10000])\n",
      "torch.Size([10000]) torch.Size([10000]) torch.Size([10000]) torch.Size([10000]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    positive_pairs, negative_pairs = generate_positive_negative_pairs(citation_network, tensor_node_features, n_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41740751564502715 0.18778504878282548 0.6931466341018677\n",
      "1049.5 231.7 3971.4 1540.3\n"
     ]
    }
   ],
   "source": [
    "graph = citation_network\n",
    "n_samples = 10000\n",
    "high_threshold = 0.5\n",
    "low_threshold = 0.3\n",
    "\n",
    "means, min, max = [], [], []\n",
    "num_5, num_55, num_3, num_25 = [], [], [], []\n",
    "for _ in range(10):\n",
    "    n_nodes = graph.number_of_nodes()\n",
    "    random_pair = torch.randint(0, n_nodes, (n_samples, 2))\n",
    "\n",
    "    src = random_pair[:, 0].numpy()\n",
    "    dst = random_pair[:, 1].numpy()\n",
    "\n",
    "    dfs = df.set_index(['src', 'dst'])\n",
    "    linked_random_pair = dfs[dfs.index.isin(list(zip(src, dst)))].reset_index()[['src', 'dst']].to_numpy()\n",
    "    linked_random_pair = torch.FloatTensor(linked_random_pair)\n",
    "\n",
    "    # linked_random_pair = torch.FloatTensor([[1,2], [2,3], [2,3]])\n",
    "    # print(linked_random_pair)\n",
    "\n",
    "    scores = similarity_score(random_pair, linked_random_pair, tensor_node_features)\n",
    "    positive_pairs = random_pair[scores > high_threshold]\n",
    "    negative_pairs = random_pair[scores < low_threshold]\n",
    "    des = pd.DataFrame(scores).describe()\n",
    "    means.append(des.loc['mean'][0])\n",
    "    min.append(des.loc['min'][0])\n",
    "    max.append(des.loc['max'][0])\n",
    "    \n",
    "    num_5.append(random_pair[scores > 0.5].shape[0])\n",
    "    num_55.append(random_pair[scores > 0.55].shape[0])\n",
    "    num_3.append(random_pair[scores < 0.4].shape[0])\n",
    "    num_25.append(random_pair[scores < 0.35].shape[0])\n",
    "    \n",
    "print(np.mean(means), np.mean(min), np.mean(max))\n",
    "print(np.mean(num_5), np.mean(num_55), np.mean(num_3), np.mean(num_25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.416557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.065432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.192632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.372048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.416801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.461001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.689285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  10000.000000\n",
       "mean       0.416557\n",
       "std        0.065432\n",
       "min        0.192632\n",
       "25%        0.372048\n",
       "50%        0.416801\n",
       "75%        0.461001\n",
       "max        0.689285"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5580, 78617]]),\n",
       " tensor([[ 80614,  75933],\n",
       "         [ 66861, 116188],\n",
       "         [ 72866,  53177]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_pairs, negative_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10000])\n",
      "tensor([ True,  True, False,  ..., False, False, False])\n",
      "torch.Size([10000])\n",
      "tensor([1.2752, 1.2189, 0.4533,  ..., 0.2656, 0.5886, 0.3431])\n",
      "tensor([0.2752, 0.2189, 0.4533,  ..., 0.2656, 0.5886, 0.3431])\n"
     ]
    }
   ],
   "source": [
    "linked_random_pair = torch.FloatTensor([[71616, 131606], [85942, 158828], [1,2], [2,3], [2,3]])\n",
    "# linked_random_pair = torch.FloatTensor([[1,2]])\n",
    "\n",
    "domains = tensor_node_features[:, 900:1200]\n",
    "domains_dissimilarity = 1 - F.cosine_similarity(domains[random_pair[:,0]], domains[random_pair[:,1]])\n",
    "\n",
    "overlap_mask = (linked_random_pair[:, None, :] == random_pair[None, :, :]).all(dim=2)\n",
    "overlap_mask_1d = overlap_mask.any(dim=0)\n",
    "weighted_link_similarity = overlap_mask_1d.float()\n",
    "\n",
    "print(overlap_mask.shape)\n",
    "print(overlap_mask_1d)\n",
    "print(weighted_link_similarity.shape)\n",
    "\n",
    "print(domains_dissimilarity + weighted_link_similarity)\n",
    "print(domains_dissimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_mask = (linked_random_pair[:, None, :] == random_pair[None, :, :]).all(dim=2)\n",
    "overlap_mask.any(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10000])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_mask = (linked_random_pair[:, None, :] == random_pair[None, :, :]).all(dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 71616, 131606],\n",
       "        [ 85942, 158828],\n",
       "        [ 94244, 121809],\n",
       "        ...,\n",
       "        [ 87891, 153233],\n",
       "        [ 30173, 111150],\n",
       "        [131268, 154469]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1273175, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
