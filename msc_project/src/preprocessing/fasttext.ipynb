{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/filtered_nodes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = list(df['title'])\n",
    "abstract_list = list(df['abstract'])\n",
    "keywords_list = list(df['keywords'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fasttext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To download fasttext pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# fasttext.util.download_model('en', if_exists='ignore')\n",
    "model = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embedding(model, keywords_list):\n",
    "    embedding = [ np.array(list(map(model.get_word_vector, keywords))) for keywords in keywords_list ]\n",
    "    return embedding\n",
    "\n",
    "def sentence_embedding(model, sentence_list):\n",
    "    embedding = [ model.get_sentence_vector(' '.join(sentence.split())) for sentence in sentence_list ]\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_embedding_list = word_embedding(model, keywords_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_embedding_mean_list = [ np.mean(keywords_embedding, axis=0) for keywords_embedding in keywords_embedding_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embedding_list = sentence_embedding(model, title_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/msc_project/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'  # You can choose other BERT variations as well\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(text, bert_tokenizer, bert_model, top_n=20):\n",
    "    inputs = bert_tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)  # Adjust max_length as needed\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "        \n",
    "        \n",
    "    # Rank tokens based on the norm of embeddings\n",
    "    norms = torch.norm(embeddings, p=2, dim=2)\n",
    "    ranked_indices = norms.argsort(descending=True).squeeze(0)\n",
    "    ranked_tokens = [ bert_tokenizer.convert_ids_to_tokens(idx.item()) for idx in ranked_indices ]\n",
    "    \n",
    "    # Filtering and post-processing\n",
    "    keywords = []\n",
    "    for token in ranked_tokens:\n",
    "        if token.startswith(\"##\"):\n",
    "            continue\n",
    "        keywords.append(token)\n",
    "        if len(keywords) == top_n:\n",
    "            break\n",
    "    \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_bert_embedding(abstract_list[0], tokenizer, model)\n",
    "abstract_keywords_list = [ get_bert_embedding(abstract, tokenizer, model) for abstract in abstract_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148061\n",
      "['[unused37]', '[unused79]', '[unused80]', '[unused11]', '[unused55]', '[unused54]', '[unused67]', '[unused56]', '[unused10]', '[unused64]', '[unused52]', '[unused53]', '[unused39]', '[unused66]', '[unused68]', '[unused38]', '[unused46]', '[unused174]', '[unused96]', '[unused65]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[unused129]',\n",
       " '[unused94]',\n",
       " '[unused130]',\n",
       " '[unused110]',\n",
       " '[unused100]',\n",
       " '[unused111]',\n",
       " '[unused131]',\n",
       " '[unused154]',\n",
       " '[unused84]',\n",
       " '[unused38]',\n",
       " '[unused95]',\n",
       " '[unused171]',\n",
       " '[unused2]',\n",
       " '[unused156]',\n",
       " '[unused102]',\n",
       " '[unused175]',\n",
       " '[unused112]',\n",
       " '[unused23]',\n",
       " '[unused128]',\n",
       " '[MASK]']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(abstract_keywords_list))\n",
    "# print(abstract_keywords_list[555])\n",
    "# abstract_embedding_list = word_embedding(abstract_keywords_list)\n",
    "\n",
    "\n",
    "get_bert_embedding(abstract_list[0], tokenizer, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [('optimization', 0.3496), ('fuzzy', 0.3013), ('optimal', 0.2961), ('objective', 0.274), ('algorithm', 0.2718), ('objectives', 0.2717), ('facilities', 0.2028), ('station', 0.1872), ('locations', 0.1841), ('location', 0.181), ('stations', 0.181), ('areas', 0.1798), ('combination', 0.1795), ('decision', 0.1747), ('multi', 0.1639), ('genetic', 0.1609), ('derbyshire', 0.1426), ('risk', 0.1421), ('application', 0.1392), ('determine', 0.1337)]\n",
      "[10] [('tensors', 0.4823), ('tensor', 0.4633), ('hyperspectral', 0.4504), ('spectral', 0.396), ('classification', 0.379), ('dimensionality', 0.3598), ('locality', 0.3264), ('supervised', 0.3139), ('discriminative', 0.2908), ('features', 0.2783), ('multilinear', 0.2643), ('imagery', 0.2526), ('learning', 0.2205), ('manifold', 0.2187), ('spectrometer', 0.2178), ('feature', 0.212), ('spatial', 0.2065), ('infrared', 0.2036), ('images', 0.1914), ('imaging', 0.1804)]\n",
      "[20] [('flow', 0.4234), ('motion', 0.421), ('tracking', 0.4194), ('segmenter', 0.3624), ('background', 0.3164), ('segment', 0.3123), ('optical', 0.2623), ('velocity', 0.2567), ('detect', 0.2436), ('moving', 0.2383), ('object', 0.2057), ('predicting', 0.1445), ('technique', 0.1289), ('techniques', 0.1173), ('regions', 0.0968), ('distinguishable', 0.0868), ('detected', 0.0753), ('propose', 0.052), ('output', 0.0447), ('new', 0.041)]\n",
      "[30] [('recognition', 0.4182), ('volumetric', 0.4044), ('volumes', 0.3183), ('decomposition', 0.3131), ('features', 0.3023), ('partitioning', 0.2931), ('form', 0.283), ('convex', 0.2766), ('shape', 0.2563), ('asvp', 0.2474), ('feature', 0.2453), ('hulls', 0.2271), ('geometric', 0.2102), ('asv', 0.2038), ('objects', 0.2031), ('recognized', 0.1941), ('spatial', 0.1841), ('boundary', 0.1716), ('object', 0.1358), ('alternating', 0.123)]\n",
      "[40] [('saliency', 0.5646), ('salient', 0.3898), ('carving', 0.3638), ('pixels', 0.2966), ('visual', 0.2879), ('visually', 0.2724), ('seam', 0.269), ('seams', 0.2431), ('edges', 0.23), ('features', 0.2275), ('grayscale', 0.2173), ('importance', 0.2122), ('prominent', 0.2062), ('preserving', 0.1998), ('maps', 0.1992), ('image', 0.1936), ('intensity', 0.1739), ('deforming', 0.1691), ('gradient', 0.1687), ('targeting', 0.167)]\n",
      "[50] [('segmentation', 0.4254), ('videos', 0.4105), ('descriptors', 0.3494), ('surveillance', 0.3376), ('frames', 0.3294), ('descriptor', 0.3291), ('video', 0.3206), ('clip', 0.3054), ('objects', 0.2762), ('contour', 0.2756), ('frame', 0.2616), ('shape', 0.2496), ('images', 0.2462), ('transforms', 0.2318), ('object', 0.2282), ('vop', 0.213), ('vops', 0.2125), ('abstraction', 0.2092), ('key', 0.1946), ('region', 0.1878)]\n",
      "[60] [('equalizer', 0.4753), ('equalizers', 0.4683), ('interference', 0.344), ('channels', 0.303), ('channel', 0.2468), ('microwave', 0.2166), ('forcing', 0.2159), ('blind', 0.1991), ('digital', 0.1864), ('estimation', 0.182), ('adaptive', 0.1511), ('intersymbol', 0.1472), ('square', 0.1302), ('reduce', 0.1281), ('fractionally', 0.12), ('estimating', 0.1147), ('statistics', 0.1102), ('fir', 0.1064), ('spaced', 0.1006), ('methods', 0.0714)]\n",
      "[70] [('gene', 0.4038), ('genes', 0.4029), ('networks', 0.3733), ('digraph', 0.3036), ('patterns', 0.2722), ('genetic', 0.2679), ('inference', 0.2598), ('boolean', 0.2489), ('network', 0.2259), ('algorithms', 0.2161), ('aignet', 0.2075), ('disruption', 0.1534), ('mechanism', 0.1394), ('reconstruct', 0.1188), ('model', 0.1136), ('wild', 0.1126), ('interrelated', 0.1049), ('static', 0.1022), ('kinds', 0.1016), ('structure', 0.1002)]\n",
      "[80] [('geostatistics', 0.6445), ('geostatistical', 0.5957), ('gstat', 0.5585), ('variograms', 0.3849), ('gis', 0.3724), ('variogram', 0.3703), ('spatial', 0.276), ('modelling', 0.2545), ('visualisation', 0.251), ('statistics', 0.2402), ('statistical', 0.2387), ('kriging', 0.2235), ('simulation', 0.2165), ('computing', 0.216), ('trend', 0.2047), ('multivariable', 0.2024), ('software', 0.2021), ('spatially', 0.1893), ('environments', 0.1892), ('indicator', 0.1757)]\n",
      "[90] [('neural', 0.3778), ('computational', 0.3675), ('computations', 0.3576), ('dimensional', 0.3405), ('recurrent', 0.3182), ('iterated', 0.3116), ('networks', 0.3111), ('piecewise', 0.31), ('universal', 0.3069), ('linear', 0.3013), ('dimension', 0.2946), ('systems', 0.2499), ('maps', 0.2335), ('monotone', 0.1965), ('complex', 0.1748), ('abilities', 0.1526), ('capable', 0.1332), ('capability', 0.1242), ('space', 0.1227), ('paper', 0.1022)]\n",
      "[100] [('recognition', 0.4171), ('descriptors', 0.3906), ('hog2', 0.3869), ('features', 0.3792), ('hog', 0.3697), ('descriptor', 0.3648), ('tracking', 0.3566), ('svm', 0.3486), ('skeleton', 0.3336), ('actions', 0.3327), ('action', 0.3259), ('feature', 0.3259), ('2d', 0.3032), ('classification', 0.3007), ('histogram', 0.2883), ('datasets', 0.2732), ('frame', 0.2617), ('images', 0.2559), ('depth', 0.2326), ('invariant', 0.2306)]\n",
      "[110] [('flickr', 0.4446), ('retrieval', 0.402), ('similarity', 0.401), ('images', 0.3375), ('topics', 0.2894), ('indexing', 0.2848), ('content', 0.2754), ('representations', 0.265), ('searching', 0.2551), ('dirichlet', 0.251), ('unsupervised', 0.2429), ('semantic', 0.2383), ('image', 0.2361), ('lda', 0.2349), ('similar', 0.2316), ('relevance', 0.2276), ('browsing', 0.2247), ('probabilistic', 0.2209), ('learning', 0.2128), ('models', 0.2048)]\n",
      "[120] [('neuron', 0.3444), ('swarm', 0.3255), ('prediction', 0.2792), ('neural', 0.279), ('algorithm', 0.2523), ('crpso', 0.2447), ('optimization', 0.2424), ('algorithms', 0.2386), ('multiplicative', 0.214), ('pso', 0.1998), ('particle', 0.1755), ('cooperative', 0.1753), ('polynomial', 0.1655), ('approximation', 0.1597), ('learning', 0.151), ('series', 0.1393), ('function', 0.1382), ('propagation', 0.1364), ('model', 0.1337), ('functions', 0.1235)]\n",
      "[130] [('mutations', 0.4104), ('mutation', 0.3678), ('gene', 0.3571), ('phenotype', 0.3364), ('genetic', 0.3151), ('predict', 0.3115), ('amino', 0.302), ('molecular', 0.3019), ('mutant', 0.2945), ('sequencing', 0.2846), ('protein', 0.284), ('nucleotide', 0.2765), ('predicted', 0.2692), ('disease', 0.2318), ('sift', 0.2134), ('genotyping', 0.2123), ('mutdb', 0.2102), ('mutpred', 0.206), ('computational', 0.2032), ('wild', 0.1934)]\n",
      "[140] [('multicast', 0.475), ('distributed', 0.3445), ('broadcast', 0.3339), ('sparse', 0.3267), ('networks', 0.3242), ('nodes', 0.3171), ('network', 0.3061), ('routing', 0.304), ('backbone', 0.2989), ('optimum', 0.268), ('scheduling', 0.259), ('minimize', 0.2487), ('weighted', 0.2455), ('costs', 0.2417), ('cost', 0.2411), ('wireless', 0.2137), ('graph', 0.2116), ('efficient', 0.2108), ('node', 0.1992), ('overlay', 0.1927)]\n",
      "[150] [('phonetic', 0.4119), ('synthesis', 0.3833), ('phonemes', 0.3793), ('waveform', 0.3365), ('speech', 0.3353), ('phoneme', 0.3304), ('waveforms', 0.2974), ('synthesized', 0.2781), ('prosodic', 0.2708), ('concatenation', 0.2623), ('tuning', 0.253), ('sounding', 0.2463), ('concatenate', 0.2392), ('sequence', 0.2228), ('search', 0.2221), ('text', 0.2126), ('units', 0.2023), ('database', 0.2016), ('unit', 0.1893), ('transition', 0.175)]\n",
      "[160] [('algorithms', 0.3842), ('nodes', 0.365), ('algorithm', 0.332), ('graph', 0.2881), ('optimisation', 0.2861), ('coordination', 0.2774), ('agents', 0.272), ('decentralised', 0.2653), ('communication', 0.2575), ('sensing', 0.2563), ('implementation', 0.2461), ('surveillance', 0.2298), ('utilities', 0.2268), ('hardware', 0.2234), ('cost', 0.2193), ('colouring', 0.218), ('benchmark', 0.1978), ('sensor', 0.1974), ('bipartite', 0.1884), ('dsa', 0.1811)]\n",
      "[170] [('motion', 0.4238), ('bayesian', 0.2938), ('posterior', 0.2625), ('detector', 0.2556), ('recognizing', 0.2521), ('probabilistic', 0.246), ('filtering', 0.2385), ('pixels', 0.2195), ('image', 0.217), ('velocities', 0.2106), ('discontinuity', 0.1964), ('models', 0.1872), ('orientation', 0.184), ('generative', 0.1751), ('particle', 0.1722), ('estimation', 0.1583), ('boundaries', 0.1374), ('discrete', 0.1295), ('algorithm', 0.1272), ('disappearance', 0.1248)]\n",
      "[180] [('optimization', 0.4734), ('rosenbrock', 0.3573), ('algorithms', 0.3355), ('evolutionary', 0.3269), ('minima', 0.3225), ('numerical', 0.2953), ('benchmark', 0.2853), ('function', 0.2699), ('unimodal', 0.2286), ('minimum', 0.2272), ('dimensional', 0.1691), ('theoretical', 0.145), ('instinct', 0.1433), ('deb', 0.1427), ('classical', 0.1415), ('analysis', 0.1394), ('variable', 0.1143), ('local', 0.1086), ('hansen', 0.1078), ('dimensions', 0.089)]\n",
      "[190] [('knapsacks', 0.7351), ('attack', 0.3705), ('iterated', 0.2909), ('heuristic', 0.2907), ('arguments', 0.1989), ('break', 0.1627), ('broken', 0.1453), ('proof', 0.1294), ('presents', 0.1161), ('examples', 0.114), ('provide', 0.1093), ('paper', 0.0965), ('detailed', 0.0936), ('works', 0.0927), ('successfully', 0.0909), ('description', 0.0872), ('outline', 0.0616), ('used', 0.0358)]\n",
      "[200] [('bayesian', 0.3701), ('integrand', 0.3602), ('sampling', 0.3601), ('importance', 0.3262), ('integrals', 0.3204), ('monte', 0.2971), ('carlo', 0.2814), ('prior', 0.28), ('marginal', 0.2781), ('statistical', 0.2774), ('models', 0.2716), ('multimodality', 0.2653), ('estimation', 0.2444), ('bmc', 0.2443), ('sample', 0.2357), ('samples', 0.2337), ('multidimensional', 0.207), ('information', 0.1998), ('knowledge', 0.1951), ('computing', 0.1858)]\n",
      "[210] [('hypergraph', 0.5398), ('clustering', 0.5229), ('partitioning', 0.3852), ('algorithms', 0.3816), ('affinity', 0.3617), ('hyperedges', 0.3372), ('algorithm', 0.3338), ('graph', 0.3167), ('pairwise', 0.2863), ('partition', 0.2815), ('vertices', 0.2654), ('relates', 0.2439), ('spectral', 0.2301), ('vision', 0.2175), ('relations', 0.181), ('weighted', 0.171), ('simultaneously', 0.1615), ('scheme', 0.1507), ('dyadic', 0.143), ('triadic', 0.1402)]\n",
      "[220] [('biogeography', 0.5146), ('optimization', 0.5043), ('algorithms', 0.4256), ('biology', 0.4154), ('biological', 0.3769), ('organisms', 0.3168), ('mathematical', 0.3028), ('neurons', 0.2825), ('mathematics', 0.2821), ('swarm', 0.2774), ('networks', 0.2761), ('neural', 0.2736), ('bbo', 0.2655), ('genetic', 0.2341), ('artificial', 0.2257), ('benchmarks', 0.2018), ('nature', 0.1942), ('methods', 0.1775), ('genetics', 0.1725), ('engine', 0.1713)]\n",
      "[230] [('reinforcement', 0.4952), ('pomdps', 0.4254), ('pomdp', 0.4162), ('planning', 0.3856), ('reward', 0.3543), ('learns', 0.3541), ('exploration', 0.3465), ('reinforce', 0.3463), ('mdps', 0.334), ('markov', 0.3189), ('mdp', 0.3187), ('adaptive', 0.3116), ('learning', 0.3029), ('planner', 0.302), ('plan', 0.2683), ('actions', 0.2635), ('bayesian', 0.2627), ('bayes', 0.2581), ('knowledge', 0.248), ('seek', 0.2454)]\n",
      "[240] [('java', 0.44), ('jdk', 0.4046), ('binaries', 0.3669), ('reusability', 0.2989), ('binary', 0.2768), ('compiled', 0.2623), ('adaptation', 0.2582), ('vm', 0.238), ('implementation', 0.234), ('compatibility', 0.2261), ('bca', 0.2163), ('components', 0.2091), ('sun', 0.2059), ('adapted', 0.1977), ('release', 0.1729), ('compatible', 0.1681), ('evolved', 0.1588), ('program', 0.1552), ('speed', 0.1535), ('usefulness', 0.1497)]\n",
      "[250] [('recognition', 0.4107), ('matching', 0.4104), ('similarity', 0.3712), ('eigenface', 0.3618), ('retrieval', 0.2631), ('nearest', 0.2554), ('face', 0.2539), ('images', 0.2278), ('projections', 0.2093), ('probabilistic', 0.1929), ('image', 0.1776), ('bayesian', 0.1654), ('pattern', 0.1591), ('norms', 0.1573), ('computational', 0.1485), ('computation', 0.1465), ('costly', 0.1381), ('map', 0.1322), ('subspace', 0.1306), ('databases', 0.1303)]\n",
      "[260] [('bist', 0.3684), ('scan', 0.3346), ('coverage', 0.2712), ('flipping', 0.2166), ('flips', 0.1966), ('hardware', 0.1937), ('fault', 0.1896), ('lfsr', 0.1658), ('circuitry', 0.1633), ('bits', 0.1407), ('random', 0.1372), ('guarantees', 0.1225), ('scheme', 0.1205), ('test', 0.113), ('experimental', 0.0895), ('probabilistic', 0.0875), ('procedure', 0.0672), ('mode', 0.0651), ('bit', 0.0471), ('function', 0.0418)]\n",
      "[270] [('virtuality', 0.5998), ('virtual', 0.5257), ('interfaces', 0.4759), ('collaboration', 0.4322), ('blending', 0.4106), ('communication', 0.3922), ('screen', 0.3849), ('objects', 0.2895), ('behaviors', 0.2856), ('reality', 0.2848), ('face', 0.259), ('users', 0.201), ('based', 0.1801), ('allowing', 0.1411), ('like', 0.1291), ('let', 0.0993)]\n",
      "[280] [('continuations', 0.6553), ('coroutine', 0.474), ('abstraction', 0.3825), ('implementing', 0.3388), ('mechanisms', 0.3093), ('functional', 0.2615), ('class', 0.1565), ('power', 0.1366), ('variety', 0.0957), ('importance', 0.0798), ('discussed', 0.0541), ('using', 0.0534), ('demonstrated', 0.0343), ('general', 0.019)]\n",
      "[290] [('anonymity', 0.554), ('protocols', 0.5107), ('csp', 0.4252), ('securityproperties', 0.4023), ('security', 0.3789), ('formally', 0.3068), ('formal', 0.2946), ('notation', 0.2574), ('property', 0.1956), ('definition', 0.1953), ('provide', 0.1846), ('necessaryto', 0.1672), ('approach', 0.1415), ('discussesthe', 0.1362), ('analyse', 0.1293), ('respect', 0.1243), ('itproposes', 0.1241), ('intendedto', 0.109), ('examples', 0.1039), ('different', 0.0896)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.240975"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "keywords_ls = []\n",
    "means = []\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "for idx, abstract in enumerate(abstract_list[:100]):\n",
    "    keywords = kw_model.extract_keywords(abstract, top_n=20, use_mmr=True)\n",
    "    keywords_ls.append(keywords)\n",
    "    \n",
    "    if idx % 10 == 0:\n",
    "        print(f\"[{idx}] {keywords}\")\n",
    "        \n",
    "    scores = list(map(float, np.array(keywords)[:, 1]))\n",
    "    mean_score = np.median(scores)\n",
    "    means.append(mean_score)\n",
    "    \n",
    "np.median(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ['optimization', 'fuzzy']\n",
      "[10] ['tensors', 'hyperspectral', 'spectral', 'classification', 'dimensionality', 'locality']\n",
      "[20] ['flow', 'motion', 'tracking', 'segmenter', 'background']\n",
      "[30] ['recognition', 'volumetric', 'decomposition']\n",
      "[40] ['saliency', 'carving']\n",
      "[50] ['segmentation', 'videos', 'surveillance', 'frames', 'descriptor', 'clip']\n",
      "[60] ['equalizer', 'interference', 'channels']\n",
      "[70] ['gene', 'networks', 'digraph']\n",
      "[80] ['geostatistics', 'gstat', 'gis', 'variogram']\n",
      "[90] ['neural', 'computational', 'dimensional', 'recurrent', 'iterated', 'networks', 'piecewise', 'universal', 'linear']\n"
     ]
    }
   ],
   "source": [
    "keywords_from_abstract = []\n",
    "threshold = 0.3\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "for abstract in abstract_list:\n",
    "    keywords = kw_model.extract_keywords(abstract, top_n=20, use_mmr=True)\n",
    "    filtered_keywords = [ keyword[0] for keyword in keywords if keyword[1] > threshold ]\n",
    "    keywords_from_abstract.append(filtered_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[0] ['optimization', 'fuzzy']\n",
      "[10] ['tensors', 'hyperspectral', 'spectral', 'classification', 'dimensionality', 'locality']\n",
      "[20] ['flow', 'motion', 'tracking', 'segmenter', 'background']\n",
      "[30] ['recognition', 'volumetric', 'decomposition']\n",
      "[40] ['saliency', 'carving']\n",
      "[50] ['segmentation', 'videos', 'surveillance', 'frames', 'descriptor', 'clip']\n",
      "[60] ['equalizer', 'interference', 'channels']\n",
      "[70] ['gene', 'networks', 'digraph']\n",
      "[80] ['geostatistics', 'gstat', 'gis', 'variogram']\n",
      "[90] ['neural', 'computational', 'dimensional', 'recurrent', 'iterated', 'networks', 'piecewise', 'universal', 'linear']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def process_abstract(idx, abstract, kw_model, threshold):\n",
    "    keywords = kw_model.extract_keywords(abstract, top_n=20, use_mmr=True)\n",
    "    filtered_keywords = [keyword[0] for keyword in keywords if keyword[1] > threshold]\n",
    "    \n",
    "    return idx, filtered_keywords\n",
    "\n",
    "threshold = 0.25\n",
    "kw_model = KeyBERT()\n",
    "results = Parallel(n_jobs=-1)(delayed(process_abstract)(idx, abstract, kw_model, threshold) for idx, abstract in enumerate(abstract_list))\n",
    "\n",
    "keywords_ls = []\n",
    "\n",
    "for idx, filtered_keywords in results:\n",
    "    keywords_ls.append(filtered_keywords)\n",
    "    \n",
    "    if idx % 10 == 0:\n",
    "        print(f\"[{idx}] {filtered_keywords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30981499999999995"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(means)\n",
    "np.quantile(means, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5314725"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = 3232\n",
    "similarity = np.dot(keywords_embedding_mean_list[rand], title_embedding_list[rand]) / (np.linalg.norm(keywords_embedding_mean_list[rand]) * np.linalg.norm(title_embedding_list[rand]))\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = np.dot(abstract_embedding_list[rand], title_embedding_list[rand]) / (np.linalg.norm(abstract_embedding_list[rand]) * np.linalg.norm(title_embedding_list[rand]))\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = np.dot(abstract_embedding_list[rand], keywords_embedding_mean_list[rand]) / (np.linalg.norm(abstract_embedding_list[rand]) * np.linalg.norm(keywords_embedding_mean_list[rand]))\n",
    "similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
