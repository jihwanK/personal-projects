{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "\n",
    "import dgl\n",
    "import dgl.data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = \"/lyceum/jhk1c21/msc_project/data\"\n",
    "filtered_path = os.path.join(data_home, \"graph\", \"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv(os.path.join(filtered_path, \"filtered_nodes.csv\"))\n",
    "ids = np.load(os.path.join(filtered_path, \"id.npy\"))\n",
    "edges = np.load(os.path.join(filtered_path, \"eleminated_edges.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['src'] = edges[:, 0]\n",
    "df['des'] = edges[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert id from str to numbers\n",
    "id_to_int = {original_id: i for i, original_id in enumerate(ids)}\n",
    "int_to_id = {i: original_id for original_id, i in id_to_int.items()}\n",
    "\n",
    "df['src'] = df['src'].apply(lambda x: id_to_int[x])\n",
    "df['des'] = df['des'].apply(lambda x: id_to_int[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = np.load(os.path.join(filtered_path, \"title.npy\"))\n",
    "keyword = np.load(os.path.join(filtered_path, \"keywords.npy\"))\n",
    "abstract = np.load(os.path.join(filtered_path, \"abstract.npy\"))\n",
    "domain = np.load(os.path.join(filtered_path, \"domain_embedding.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148039"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_network = dgl.DGLGraph( (df['src'], df['des']) )\n",
    "# citation_network = dgl.graph( (df['src'], df['des']) )\n",
    "\n",
    "citation_network.ndata['title'] = torch.tensor(title)\n",
    "citation_network.ndata['keyword'] = torch.tensor(keyword)\n",
    "citation_network.ndata['abstract'] = torch.tensor(abstract)\n",
    "citation_network.ndata['domain'] = torch.tensor(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=148039, num_edges=1412315,\n",
       "      ndata_schemes={'title': Scheme(shape=(300,), dtype=torch.float32), 'keyword': Scheme(shape=(300,), dtype=torch.float32), 'abstract': Scheme(shape=(300,), dtype=torch.float32), 'domain': Scheme(shape=(300,), dtype=torch.float32)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import GATConv\n",
    "\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.gatconv = GATConv(in_dim, out_dim, num_heads=1)\n",
    "        \n",
    "    def forward(self, g, h):\n",
    "        h = self.gatconv(g, h)\n",
    "        return h.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute similarity for titles, abstracts, keywords, and domains\n",
    "def compute_similarity(node1, node2):\n",
    "    title_similarity = cosine_similarity([node1['title']], [node2['title']])[0][0]\n",
    "    abstract_similarity = cosine_similarity([node1['abstract']], [node2['abstract']])[0][0]\n",
    "    keyword_similarity = cosine_similarity([node1['keywords']], [node2['keywords']])[0][0]\n",
    "    domain_dissimilarity = 1 - cosine_similarity([node1['domain']], [node2['domain']])[0][0]\n",
    "    \n",
    "    # Combine these based on your specific needs\n",
    "    return title_similarity + abstract_similarity + keyword_similarity - domain_dissimilarity\n",
    "\n",
    "# Initialize lists to hold pairs and labels\n",
    "pairs = []\n",
    "labels = []\n",
    "\n",
    "# Loop over edges in the graph to create pairs and labels\n",
    "for u, v in zip(edges[:, 0], edges[:, 1]):\n",
    "    node1 = {'title': titles[u], 'abstract': abstracts[u], 'keywords': keywords[u], 'domain': domains[u]}\n",
    "    node2 = {'title': titles[v], 'abstract': abstracts[v], 'keywords': keywords[v], 'domain': domains[v]}\n",
    "    \n",
    "    similarity = compute_similarity(node1, node2)\n",
    "    \n",
    "    # Based on a threshold, decide if the pair is similar or dissimilar\n",
    "    if similarity > 0.5:  # This is a threshold you can tune\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)\n",
    "        \n",
    "    pairs.append((u, v))\n",
    "\n",
    "# Convert pairs and labels to tensors\n",
    "pairs = torch.LongTensor(pairs)\n",
    "labels = torch.FloatTensor(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and loss\n",
    "model = GATModel(300, 128, 64)  # Assuming node feature size is 300\n",
    "loss_fn = ContrastiveLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    # Forward pass\n",
    "    h = torch.FloatTensor(g.ndata['title'])  # Assuming titles are used as node features\n",
    "    output = model(g, h)\n",
    "    \n",
    "    # Compute contrastive loss\n",
    "    # Here you would prepare your 'output1', 'output2' and 'label' tensors based on your specific use-case\n",
    "    loss = loss_fn(output1, output2, label)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.layer1 = GATLayer(in_dim, hidden_dim)\n",
    "        self.layer2 = GATLayer(hidden_dim, out_dim)\n",
    "        \n",
    "    def forward(self, g, h):\n",
    "        h = F.relu(self.layer1(g, h))\n",
    "        h = self.layer2(g, h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dgl.nn import GATConv\n",
    "\n",
    "class GATModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_heads):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.gat1 = GATConv(in_dim, hidden_dim, num_heads)\n",
    "        self.gat2 = GATConv(hidden_dim * num_heads, out_dim, 1)\n",
    "        \n",
    "    def forward(self, g, h):\n",
    "        h = self.gat1(g, h).flatten(1)\n",
    "        h = F.elu(h)\n",
    "        h = self.gat2(g, h).squeeze(1)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(edges, node_embeddings, domain_data):\n",
    "    citing_indices = edges[0]\n",
    "    cited_indices = edges[1]\n",
    "    \n",
    "    citing_embeddings = node_embeddings[citing_indices]\n",
    "    cited_embeddings = node_embeddings[cited_indices]\n",
    "    \n",
    "    # Calculate similarity score using cosine similarity\n",
    "    similarity_score = F.cosine_similarity(citing_embeddings, cited_embeddings, dim=1)\n",
    "    \n",
    "    # Calculate domain difference\n",
    "    citing_domains = domain_data[citing_indices]\n",
    "    cited_domains = domain_data[cited_indices]\n",
    "    domain_difference = calculate_domain_difference(citing_domains, cited_domains)\n",
    "    \n",
    "    # Custom Loss: This is just an example; you might want to use a different form\n",
    "    loss = -torch.sum(similarity_score / (1 + domain_difference))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and optimizer\n",
    "model = GATModel(in_dim=128, hidden_dim=64, out_dim=32, num_heads=4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    node_embeddings = model(g, g.ndata['feature'])\n",
    "    \n",
    "    # Calculate loss\n",
    "    edges = g.edges()\n",
    "    loss = custom_loss(edges, node_embeddings, domain_data)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Loss function] Contrastive learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TripletMarginLoss\n",
    "\n",
    "# Initialize the loss function\n",
    "triplet_loss = TripletMarginLoss(margin=1.0, p=2)\n",
    "\n",
    "# Forward pass through GAT to get embeddings\n",
    "anchor_embeddings = gat_model(graph, anchor_features)\n",
    "positive_embeddings = gat_model(graph, positive_features)\n",
    "negative_embeddings = gat_model(graph, negative_features)\n",
    "\n",
    "# Compute the loss\n",
    "loss = triplet_loss(anchor_embeddings, positive_embeddings, negative_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
