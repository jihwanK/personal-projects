{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac0328f2-a24b-45ce-8915-8115cafd4d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lyceum/jhk1c21/.conda/envs/msc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea33465-6feb-4838-b8b8-9ee1b2239aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "502c6414-db17-4152-8704-62990c0589a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lyceum/jhk1c21/msc_project/data/graph/hellop'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_home = \"/lyceum/jhk1c21/msc_project/data\"\n",
    "graph_dir = os.path.join(data_home, 'graph')\n",
    "graph_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c71621f-104e-48e9-8140-1d4c80ec08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings\n",
    "title_embeddings = np.load(os.path.join(data_home, 'graph', 'title.npy'))\n",
    "keywords_embeddings = np.load(os.path.join(data_home, 'graph', 'keywords.npy'))\n",
    "abstract_embeddings = np.load(os.path.join(data_home, 'graph', 'abstract.npy'))\n",
    "\n",
    "# load files\n",
    "filtered_id = np.load(os.path.join(data_home, 'graph', 'id.npy'))\n",
    "edges = np.load(os.path.join(data_home, 'graph', 'edges.npy'))\n",
    "with open(os.path.join(data_home, 'graph', 'fos.npy'), 'rb') as f:\n",
    "    domains = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24340566-cff4-47f4-8555-1827489591a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dict = { id: title for id, title in zip(filtered_id, title_embeddings) }\n",
    "keywords_dict = { id: title for id, title in zip(filtered_id, keywords_embeddings) }\n",
    "abstract_dict = { id: title for id, title in zip(filtered_id, abstract_embeddings) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fecddaa5-c8cb-49a1-b36f-7c9c010f6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_node_ids = set([edge[0] for edge in edges] + [edge[1] for edge in edges])\n",
    "unique_node_ids = list(unique_node_ids & set(filtered_id))\n",
    "node_to_int = {node_id: i for i, node_id in enumerate(unique_node_ids)}\n",
    "\n",
    "# Convert edges with string node IDs to integer node IDs\n",
    "edges_int = []\n",
    "for src, tgt in edges:\n",
    "    src_id = node_to_int.get(src, -1)\n",
    "    tgt_id = node_to_int.get(tgt, -1)\n",
    "\n",
    "    if (src_id == -1) or (tgt_id == -1):\n",
    "        continue\n",
    "    else:\n",
    "        edges_int.append( (node_to_int[src], node_to_int[tgt]) )\n",
    "\n",
    "\n",
    "# htable_idx_to_id = { i: item for i, item in enumerate(filtered_id) }\n",
    "# htable_id_to_idx = { item: i for i, item in enumerate(filtered_id) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc0947a-280b-4281-af10-8c4cd9d21704",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m node_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([title_embeddings, keywords_embeddings, abstract_embeddings], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Convert edge information to a torch tensor\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43medges_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert node features to torch tensor\u001b[39;00m\n\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(node_features, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/torch/cuda/__init__.py:247\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    246\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 247\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    251\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "# Combine embeddings\n",
    "node_features = np.concatenate([title_embeddings, keywords_embeddings, abstract_embeddings], axis=1)\n",
    "\n",
    "# Convert edge information to a torch tensor\n",
    "edge_index = torch.tensor(edges_int, dtype=torch.long).t().contiguous().to(device)\n",
    "\n",
    "# Convert node features to torch tensor\n",
    "x = torch.tensor(node_features, dtype=torch.float32).to(device)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d6951-5c77-4213-945e-9bbf16d3cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf87db16-f8e3-403a-9921-329b42b3a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique domain to integer mapping\n",
    "all_domains = set(domain for sublist in domains for domain in sublist)\n",
    "domain_to_int = {domain: i for i, domain in enumerate(all_domains)}\n",
    "\n",
    "num_domains = len(all_domains)\n",
    "num_papers = len(domains)\n",
    "\n",
    "domain_matrix = np.zeros((num_papers, num_domains), dtype=np.float16)\n",
    "for paper_idx, paper_domains in enumerate(domains):\n",
    "    for domain in paper_domains:\n",
    "        domain_matrix[paper_idx][domain_to_int[domain]] = 1\n",
    "\n",
    "domain_matrix = torch.tensor(domain_matrix).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26e39f-fe61-4208-8d44-b06fd6e4afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_loss(embeddings):\n",
    "    dot_product = torch.mm(embeddings, embeddings.t())\n",
    "    shared_domains = torch.mm(domain_matrix, domain_matrix.t())\n",
    "    different_domains = 1 - shared_domains\n",
    "    dissimilarity = 1 - dot_product\n",
    "    loss = (dissimilarity * different_domains).sum()  # Penalize similarity for different domains\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea239af-b57b-44a8-a6d8-09e3a4889d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GNN model\n",
    "in_channels = data.x.size(1)\n",
    "model = GNN(in_channels=in_channels, hidden_channels=64, out_channels=in_channels)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = domain_loss(out)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
