{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import dgl\n",
    "from dgl.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if device == \"cpu\":\n",
    "#     print(\"device CPU\")\n",
    "#     exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HOME = \"/lyceum/jhk1c21/msc_project/data\"\n",
    "V14_PATH = os.path.join(DATA_HOME, \"graph\", \"v14\")\n",
    "FILTERED_PATH = os.path.join(V14_PATH, \"filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "nodes = pd.read_csv(os.path.join(V14_PATH, \"nodes_v14.csv\"), index_col='id')\n",
    "similarity = pd.read_csv(os.path.join(FILTERED_PATH, \"similarity_edges.csv\"))\n",
    "\n",
    "titles = np.load(os.path.join(FILTERED_PATH, 'title_embedding.npy'))\n",
    "abstracts = np.load(os.path.join(FILTERED_PATH, 'abstract_embedding.npy'))\n",
    "keywords = np.load(os.path.join(FILTERED_PATH, 'keywords_embedding.npy'))\n",
    "domains = np.load(os.path.join(FILTERED_PATH, 'domains_embedding.npy'))\n",
    "\n",
    "ids = np.load(os.path.join(FILTERED_PATH, \"filtered_id.npy\"))\n",
    "edges = np.load(os.path.join(FILTERED_PATH, 'filtered_edge.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['src'] = edges[:, 0]\n",
    "df['dst'] = edges[:, 1]\n",
    "\n",
    "# convert id from str to numbers\n",
    "id_to_int = {original_id: i for i, original_id in enumerate(ids)}\n",
    "int_to_id = {i: original_id for original_id, i in id_to_int.items()}\n",
    "\n",
    "df['src'] = df['src'].apply(lambda x: id_to_int[x])\n",
    "df['dst'] = df['dst'].apply(lambda x: id_to_int[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity for titles, abstracts, keywords, and domains\n",
    "def compute_each_similarity(node1, node2):\n",
    "    title_similarity = cosine_similarity([node1['title']], [node2['title']])[0][0]\n",
    "    abstract_similarity = cosine_similarity([node1['abstract']], [node2['abstract']])[0][0]\n",
    "    keyword_similarity = cosine_similarity([node1['keywords']], [node2['keywords']])[0][0]\n",
    "    domain_dissimilarity = 1 - cosine_similarity([node1['domain']], [node2['domain']])[0][0]\n",
    "\n",
    "    return title_similarity, abstract_similarity, keyword_similarity, domain_dissimilarity\n",
    "\n",
    "def compute_similarity(node1, node2):\n",
    "    title_similarity, abstract_similarity, keyword_similarity, domain_dissimilarity = compute_each_similarity(node1, node2)\n",
    "    \n",
    "    return title_similarity + abstract_similarity + keyword_similarity + domain_dissimilarity\n",
    "\n",
    "# Compute similarity for titles, abstracts, keywords, and domains\n",
    "def compute_weighted_similarity(node1, node2):\n",
    "    title_similarity, abstract_similarity, keyword_similarity, domain_dissimilarity = compute_each_similarity(node1, node2)\n",
    "    w1, w2, w3, w4 = 0.25, 0.15, 0.2, 0.4\n",
    "\n",
    "    return w1*title_similarity + w2*abstract_similarity + w3*keyword_similarity + w4*domain_dissimilarity\n",
    "\n",
    "# Compute similarity for titles, abstracts, keywords, and domains\n",
    "def compute_df_similarity(sim_df, weight=None):\n",
    "    if weight is None:\n",
    "        w1, w2, w3, w4 = 0.25, 0.25, 0.25, 0.25\n",
    "    else:\n",
    "        w1, w2, w3, w4 = weight\n",
    "\n",
    "    return w1*sim_df['title'] + w2*sim_df['abstract'] + w3*sim_df['keyword'] + w4*(1-sim_df['domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(node1, node2):\n",
    "    title_similarity = F.cosine_similarity([node1['title']], [node2['title']])[0][0]\n",
    "    abstract_similarity = F.cosine_similarity([node1['abstract']], [node2['abstract']])[0][0]\n",
    "    keyword_similarity = F.cosine_similarity([node1['keywords']], [node2['keywords']])[0][0]\n",
    "    domain_dissimilarity = 1 - F.cosine_similarity([node1['domain']], [node2['domain']])[0][0]\n",
    "    \n",
    "    return title_similarity, abstract_similarity, keyword_similarity, domain_dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity['weighted_similarity'] = compute_df_similarity(similarity, (0.25, 0.15, 0.2, 0.4))\n",
    "similarity['similarity'] = compute_df_similarity(similarity)\n",
    "\n",
    "similarity_list = list(similarity['similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keyword</th>\n",
       "      <th>domain</th>\n",
       "      <th>weighted_similarity</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53e99beab7602d9702497a80</td>\n",
       "      <td>53e9a4c0b7602d9702ddf482</td>\n",
       "      <td>0.470632</td>\n",
       "      <td>0.124602</td>\n",
       "      <td>0.634944</td>\n",
       "      <td>0.445128</td>\n",
       "      <td>0.485286</td>\n",
       "      <td>0.446262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53e9a1d5b7602d9702ad2aa6</td>\n",
       "      <td>558aec6284ae84d265c0707c</td>\n",
       "      <td>0.363818</td>\n",
       "      <td>0.738057</td>\n",
       "      <td>0.825033</td>\n",
       "      <td>0.803241</td>\n",
       "      <td>0.445373</td>\n",
       "      <td>0.530917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53e9abc9b7602d970357a86b</td>\n",
       "      <td>557d23366feeaa8086da70ff</td>\n",
       "      <td>0.549633</td>\n",
       "      <td>0.203248</td>\n",
       "      <td>0.594433</td>\n",
       "      <td>0.879736</td>\n",
       "      <td>0.334888</td>\n",
       "      <td>0.366895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53e9b708b7602d970429d764</td>\n",
       "      <td>53e9b5d4b7602d97041251f3</td>\n",
       "      <td>0.600002</td>\n",
       "      <td>0.239508</td>\n",
       "      <td>0.842274</td>\n",
       "      <td>0.688702</td>\n",
       "      <td>0.478901</td>\n",
       "      <td>0.498270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53e9bc1bb7602d9704883a9c</td>\n",
       "      <td>53e9ba39b7602d9704648483</td>\n",
       "      <td>0.568734</td>\n",
       "      <td>0.682352</td>\n",
       "      <td>0.832233</td>\n",
       "      <td>0.852411</td>\n",
       "      <td>0.470019</td>\n",
       "      <td>0.557727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273170</th>\n",
       "      <td>53e9ad47b7602d970372c2bd</td>\n",
       "      <td>53e9ab6fb7602d970350e269</td>\n",
       "      <td>0.684507</td>\n",
       "      <td>0.129349</td>\n",
       "      <td>0.513802</td>\n",
       "      <td>0.881588</td>\n",
       "      <td>0.340654</td>\n",
       "      <td>0.361518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273171</th>\n",
       "      <td>53e9abf1b7602d97035afe55</td>\n",
       "      <td>53e9aa79b7602d97033ef136</td>\n",
       "      <td>0.524307</td>\n",
       "      <td>0.402008</td>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.722187</td>\n",
       "      <td>0.342391</td>\n",
       "      <td>0.350892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273172</th>\n",
       "      <td>5a260c2e17c44a4ba8a24152</td>\n",
       "      <td>53e99b31b7602d97023ce813</td>\n",
       "      <td>0.499875</td>\n",
       "      <td>0.309166</td>\n",
       "      <td>0.822491</td>\n",
       "      <td>0.854233</td>\n",
       "      <td>0.394148</td>\n",
       "      <td>0.444325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273173</th>\n",
       "      <td>599c77fa601a182cd2590dbc</td>\n",
       "      <td>53e9b903b7602d97044e594e</td>\n",
       "      <td>0.525179</td>\n",
       "      <td>0.415119</td>\n",
       "      <td>0.722028</td>\n",
       "      <td>0.705364</td>\n",
       "      <td>0.455823</td>\n",
       "      <td>0.489240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273174</th>\n",
       "      <td>53e9ba60b7602d9704679fc3</td>\n",
       "      <td>53e9b4f5b7602d970402251c</td>\n",
       "      <td>0.646922</td>\n",
       "      <td>0.458240</td>\n",
       "      <td>0.694298</td>\n",
       "      <td>0.664355</td>\n",
       "      <td>0.503584</td>\n",
       "      <td>0.533776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1273175 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              src                       dst     title  \\\n",
       "0        53e99beab7602d9702497a80  53e9a4c0b7602d9702ddf482  0.470632   \n",
       "1        53e9a1d5b7602d9702ad2aa6  558aec6284ae84d265c0707c  0.363818   \n",
       "2        53e9abc9b7602d970357a86b  557d23366feeaa8086da70ff  0.549633   \n",
       "3        53e9b708b7602d970429d764  53e9b5d4b7602d97041251f3  0.600002   \n",
       "4        53e9bc1bb7602d9704883a9c  53e9ba39b7602d9704648483  0.568734   \n",
       "...                           ...                       ...       ...   \n",
       "1273170  53e9ad47b7602d970372c2bd  53e9ab6fb7602d970350e269  0.684507   \n",
       "1273171  53e9abf1b7602d97035afe55  53e9aa79b7602d97033ef136  0.524307   \n",
       "1273172  5a260c2e17c44a4ba8a24152  53e99b31b7602d97023ce813  0.499875   \n",
       "1273173  599c77fa601a182cd2590dbc  53e9b903b7602d97044e594e  0.525179   \n",
       "1273174  53e9ba60b7602d9704679fc3  53e9b4f5b7602d970402251c  0.646922   \n",
       "\n",
       "         abstract   keyword    domain  weighted_similarity  similarity  \n",
       "0        0.124602  0.634944  0.445128             0.485286    0.446262  \n",
       "1        0.738057  0.825033  0.803241             0.445373    0.530917  \n",
       "2        0.203248  0.594433  0.879736             0.334888    0.366895  \n",
       "3        0.239508  0.842274  0.688702             0.478901    0.498270  \n",
       "4        0.682352  0.832233  0.852411             0.470019    0.557727  \n",
       "...           ...       ...       ...                  ...         ...  \n",
       "1273170  0.129349  0.513802  0.881588             0.340654    0.361518  \n",
       "1273171  0.402008  0.199441  0.722187             0.342391    0.350892  \n",
       "1273172  0.309166  0.822491  0.854233             0.394148    0.444325  \n",
       "1273173  0.415119  0.722028  0.705364             0.455823    0.489240  \n",
       "1273174  0.458240  0.694298  0.664355             0.503584    0.533776  \n",
       "\n",
       "[1273175 rows x 8 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_title = torch.FloatTensor(titles)\n",
    "tensor_abstract = torch.FloatTensor(abstracts)\n",
    "tensor_keywords = torch.FloatTensor(keywords)\n",
    "tensor_domain = torch.FloatTensor(domains)\n",
    "\n",
    "node_features = np.concatenate([tensor_title, tensor_abstract, tensor_keywords, tensor_domain], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0068,  0.0102,  0.0072,  ...,  0.0114,  0.0097,  0.0002],\n",
      "        [-0.0193,  0.0117, -0.0003,  ...,  0.0161,  0.0130, -0.0064],\n",
      "        [-0.0158,  0.0258,  0.0063,  ...,  0.0371, -0.0089, -0.0235],\n",
      "        ...,\n",
      "        [-0.0039,  0.0172,  0.0035,  ...,  0.0067,  0.0091,  0.0054],\n",
      "        [-0.0116,  0.0055,  0.0058,  ...,  0.0183,  0.0149, -0.0040],\n",
      "        [-0.0041,  0.0014,  0.0039,  ...,  0.0138,  0.0155, -0.0062]])\n",
      "torch.Size([162207, 300])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_domain.view(tensor_domain.shape[0], -1))\n",
    "print(tensor_domain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DGL graph\n",
    "citation_network = dgl.graph( (df['src'], df['dst']) )\n",
    "\n",
    "citation_network.ndata['features'] = torch.FloatTensor(node_features)\n",
    "# citation_network.ndata['title'] = torch.FloatTensor(titles)\n",
    "# citation_network.ndata['abstract'] = torch.FloatTensor(abstracts)\n",
    "# citation_network.ndata['keywords'] = torch.FloatTensor(keywords)\n",
    "# citation_network.ndata['domain'] = torch.FloatTensor(domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_network.edata['weight'] = torch.FloatTensor(similarity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=162207, num_edges=1273175,\n",
       "      ndata_schemes={'title': Scheme(shape=(300,), dtype=torch.float32), 'abstract': Scheme(shape=(300,), dtype=torch.float32), 'keywords': Scheme(shape=(300,), dtype=torch.float32), 'domain': Scheme(shape=(300,), dtype=torch.float32)}\n",
       "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float32)})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citation_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL STARTS\n",
    "# GAT Layer\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_heads=1):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.gatconv = GATConv(in_dim, out_dim, num_heads, allow_zero_in_degree=True)\n",
    "        \n",
    "    def forward(self, g, h):\n",
    "        h = self.gatconv(g, h)\n",
    "        return h.squeeze(1)\n",
    "\n",
    "# GAT Model\n",
    "class GATModel(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_heads):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.layer1 = GATLayer(in_dim, hidden_dim, num_heads)\n",
    "        self.layer2 = GATLayer(hidden_dim, out_dim)\n",
    "        \n",
    "    def forward(self, g, h):\n",
    "        h = F.relu(self.layer1(g, h))\n",
    "        h = self.layer2(g, h)\n",
    "        return h\n",
    "    \n",
    "# Contrastive Loss\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(similarity.shape[0])\n",
    "labels[list(similarity[similarity['similarity'] <= 0.5].index)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(zip(df['src'], df['dst']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pairs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mLongTensor(pairs)\n\u001b[1;32m      2\u001b[0m labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(labels)\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "pairs = torch.LongTensor(pairs)\n",
    "labels = torch.FloatTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(similarity.shape[0])\n",
    "labels[list(similarity[similarity['similarity'] <= 0.5].index)] = 1\n",
    "pairs = list(zip(df['src'], df['dst']))\n",
    "\n",
    "# Convert pairs and labels to tensors\n",
    "pairs = torch.LongTensor(pairs)\n",
    "labels = torch.FloatTensor(labels)\n",
    "\n",
    "torch.save(pairs, os.path.join(V14_PATH, \"result\", \"pairs.pt\"))\n",
    "torch.save(labels, os.path.join(V14_PATH, \"result\", \"labels.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.4656655192375183\n",
      "Epoch 1, Loss: 0.4526820778846741\n",
      "Epoch 2, Loss: 0.43969765305519104\n",
      "Epoch 3, Loss: 0.4270704686641693\n",
      "Epoch 4, Loss: 0.41504502296447754\n",
      "Epoch 5, Loss: 0.4038435220718384\n",
      "Epoch 6, Loss: 0.39373674988746643\n",
      "Epoch 7, Loss: 0.3849829137325287\n",
      "Epoch 8, Loss: 0.37778109312057495\n",
      "Epoch 9, Loss: 0.37221482396125793\n",
      "Epoch 10, Loss: 0.36811766028404236\n",
      "Epoch 11, Loss: 0.36504703760147095\n",
      "Epoch 12, Loss: 0.36251315474510193\n",
      "Epoch 13, Loss: 0.360110878944397\n",
      "Epoch 14, Loss: 0.3575690984725952\n",
      "Epoch 15, Loss: 0.3547358214855194\n",
      "Epoch 16, Loss: 0.35156479477882385\n",
      "Epoch 17, Loss: 0.3480900228023529\n",
      "Epoch 18, Loss: 0.3443974256515503\n",
      "Epoch 19, Loss: 0.34060609340667725\n",
      "Epoch 20, Loss: 0.3368392884731293\n",
      "Epoch 21, Loss: 0.3332182466983795\n",
      "Epoch 22, Loss: 0.32984036207199097\n",
      "Epoch 23, Loss: 0.3267745077610016\n",
      "Epoch 24, Loss: 0.32406291365623474\n",
      "Epoch 25, Loss: 0.3217199444770813\n",
      "Epoch 26, Loss: 0.3197348415851593\n",
      "Epoch 27, Loss: 0.31809258460998535\n",
      "Epoch 28, Loss: 0.3167188763618469\n",
      "Epoch 29, Loss: 0.31555619835853577\n",
      "Epoch 30, Loss: 0.3145483732223511\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     29\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 30\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     32\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mVALIDATION START\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    393\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pairs = torch.load(os.path.join(V14_PATH, \"result\", \"pairs.pt\"))\n",
    "# labels = torch.load(os.path.join(V14_PATH, \"result\", \"labels.pt\"))\n",
    "\n",
    "# Initialize the model and loss\n",
    "# INPUT: (Feature Dim, Hidden Dim, Output Dim)\n",
    "model = GATModel(300, 128, 64)\n",
    "loss_fn = ContrastiveLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    h = torch.FloatTensor(citation_network.ndata['title'])\n",
    "    output = model(citation_network, h)\n",
    "    \n",
    "    # Create output1 and output2 based on pairs\n",
    "    output1 = output[pairs[:, 0]]\n",
    "    output2 = output[pairs[:, 1]]\n",
    "    \n",
    "    # Compute contrastive loss\n",
    "    loss = loss_fn(output1, output2, labels)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TEST START\")\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_similarity</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.273175e+06</td>\n",
       "      <td>1.273175e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.407042e-01</td>\n",
       "      <td>4.759605e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.233094e-02</td>\n",
       "      <td>8.558922e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.165398e-01</td>\n",
       "      <td>1.015561e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.916829e-01</td>\n",
       "      <td>4.178960e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.395954e-01</td>\n",
       "      <td>4.736374e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.883887e-01</td>\n",
       "      <td>5.318742e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.972142e-01</td>\n",
       "      <td>8.458895e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weighted_similarity    similarity\n",
       "count         1.273175e+06  1.273175e+06\n",
       "mean          4.407042e-01  4.759605e-01\n",
       "std           7.233094e-02  8.558922e-02\n",
       "min           1.165398e-01  1.015561e-01\n",
       "25%           3.916829e-01  4.178960e-01\n",
       "50%           4.395954e-01  4.736374e-01\n",
       "75%           4.883887e-01  5.318742e-01\n",
       "max           7.972142e-01  8.458895e-01"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity[['weighted_similarity', 'similarity']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_each_similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m node1 \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m: titles[i], \u001b[39m'\u001b[39m\u001b[39mabstract\u001b[39m\u001b[39m'\u001b[39m: abstracts[i], \u001b[39m'\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m'\u001b[39m: keywords[i] ,\u001b[39m'\u001b[39m\u001b[39mdomain\u001b[39m\u001b[39m'\u001b[39m: domains[i]}\n\u001b[1;32m      5\u001b[0m node2 \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m: titles[j], \u001b[39m'\u001b[39m\u001b[39mabstract\u001b[39m\u001b[39m'\u001b[39m: abstracts[j], \u001b[39m'\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m'\u001b[39m: keywords[j] ,\u001b[39m'\u001b[39m\u001b[39mdomain\u001b[39m\u001b[39m'\u001b[39m: domains[j]}\n\u001b[0;32m----> 6\u001b[0m t, a, k, d \u001b[39m=\u001b[39m compute_each_similarity(node1, node2)\n\u001b[1;32m      7\u001b[0m tt\u001b[39m.\u001b[39mappend(t)\n\u001b[1;32m      8\u001b[0m aa\u001b[39m.\u001b[39mappend(a)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_each_similarity' is not defined"
     ]
    }
   ],
   "source": [
    "tt, aa, kk, dd = [], [], [], []\n",
    "for i in range(100):\n",
    "    for j in range(i, 1000):\n",
    "        node1 = {'title': titles[i], 'abstract': abstracts[i], 'keywords': keywords[i] ,'domain': domains[i]}\n",
    "        node2 = {'title': titles[j], 'abstract': abstracts[j], 'keywords': keywords[j] ,'domain': domains[j]}\n",
    "        t, a, k, d = compute_each_similarity(node1, node2)\n",
    "        tt.append(t)\n",
    "        aa.append(a)\n",
    "        kk.append(k)\n",
    "        dd.append(d)\n",
    "        print(t, a, k, d)\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['title'] = tt\n",
    "df['abstract'] = aa\n",
    "df['keyword'] = kk\n",
    "df['domain'] = dd\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>dst</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keyword</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53e99beab7602d9702497a80</td>\n",
       "      <td>53e9a4c0b7602d9702ddf482</td>\n",
       "      <td>0.470632</td>\n",
       "      <td>0.124602</td>\n",
       "      <td>0.634944</td>\n",
       "      <td>0.445128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53e9a1d5b7602d9702ad2aa6</td>\n",
       "      <td>558aec6284ae84d265c0707c</td>\n",
       "      <td>0.363818</td>\n",
       "      <td>0.738057</td>\n",
       "      <td>0.825033</td>\n",
       "      <td>0.803241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53e9abc9b7602d970357a86b</td>\n",
       "      <td>557d23366feeaa8086da70ff</td>\n",
       "      <td>0.549633</td>\n",
       "      <td>0.203248</td>\n",
       "      <td>0.594433</td>\n",
       "      <td>0.879736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53e9b708b7602d970429d764</td>\n",
       "      <td>53e9b5d4b7602d97041251f3</td>\n",
       "      <td>0.600002</td>\n",
       "      <td>0.239508</td>\n",
       "      <td>0.842274</td>\n",
       "      <td>0.688702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53e9bc1bb7602d9704883a9c</td>\n",
       "      <td>53e9ba39b7602d9704648483</td>\n",
       "      <td>0.568734</td>\n",
       "      <td>0.682352</td>\n",
       "      <td>0.832233</td>\n",
       "      <td>0.852411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273170</th>\n",
       "      <td>53e9ad47b7602d970372c2bd</td>\n",
       "      <td>53e9ab6fb7602d970350e269</td>\n",
       "      <td>0.684507</td>\n",
       "      <td>0.129349</td>\n",
       "      <td>0.513802</td>\n",
       "      <td>0.881588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273171</th>\n",
       "      <td>53e9abf1b7602d97035afe55</td>\n",
       "      <td>53e9aa79b7602d97033ef136</td>\n",
       "      <td>0.524307</td>\n",
       "      <td>0.402008</td>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.722187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273172</th>\n",
       "      <td>5a260c2e17c44a4ba8a24152</td>\n",
       "      <td>53e99b31b7602d97023ce813</td>\n",
       "      <td>0.499875</td>\n",
       "      <td>0.309166</td>\n",
       "      <td>0.822491</td>\n",
       "      <td>0.854233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273173</th>\n",
       "      <td>599c77fa601a182cd2590dbc</td>\n",
       "      <td>53e9b903b7602d97044e594e</td>\n",
       "      <td>0.525179</td>\n",
       "      <td>0.415119</td>\n",
       "      <td>0.722028</td>\n",
       "      <td>0.705364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273174</th>\n",
       "      <td>53e9ba60b7602d9704679fc3</td>\n",
       "      <td>53e9b4f5b7602d970402251c</td>\n",
       "      <td>0.646922</td>\n",
       "      <td>0.458240</td>\n",
       "      <td>0.694298</td>\n",
       "      <td>0.664355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1273175 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              src                       dst     title  \\\n",
       "0        53e99beab7602d9702497a80  53e9a4c0b7602d9702ddf482  0.470632   \n",
       "1        53e9a1d5b7602d9702ad2aa6  558aec6284ae84d265c0707c  0.363818   \n",
       "2        53e9abc9b7602d970357a86b  557d23366feeaa8086da70ff  0.549633   \n",
       "3        53e9b708b7602d970429d764  53e9b5d4b7602d97041251f3  0.600002   \n",
       "4        53e9bc1bb7602d9704883a9c  53e9ba39b7602d9704648483  0.568734   \n",
       "...                           ...                       ...       ...   \n",
       "1273170  53e9ad47b7602d970372c2bd  53e9ab6fb7602d970350e269  0.684507   \n",
       "1273171  53e9abf1b7602d97035afe55  53e9aa79b7602d97033ef136  0.524307   \n",
       "1273172  5a260c2e17c44a4ba8a24152  53e99b31b7602d97023ce813  0.499875   \n",
       "1273173  599c77fa601a182cd2590dbc  53e9b903b7602d97044e594e  0.525179   \n",
       "1273174  53e9ba60b7602d9704679fc3  53e9b4f5b7602d970402251c  0.646922   \n",
       "\n",
       "         abstract   keyword    domain  \n",
       "0        0.124602  0.634944  0.445128  \n",
       "1        0.738057  0.825033  0.803241  \n",
       "2        0.203248  0.594433  0.879736  \n",
       "3        0.239508  0.842274  0.688702  \n",
       "4        0.682352  0.832233  0.852411  \n",
       "...           ...       ...       ...  \n",
       "1273170  0.129349  0.513802  0.881588  \n",
       "1273171  0.402008  0.199441  0.722187  \n",
       "1273172  0.309166  0.822491  0.854233  \n",
       "1273173  0.415119  0.722028  0.705364  \n",
       "1273174  0.458240  0.694298  0.664355  \n",
       "\n",
       "[1273175 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[39myield\u001b[39;00m key, cache[key]\n\u001b[1;32m     14\u001b[0m similarities \u001b[39m=\u001b[39m compute_similarities()\n\u001b[0;32m---> 15\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(similarities)\n\u001b[1;32m     16\u001b[0m df\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/pandas/core/frame.py:774\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m         data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(data)\n\u001b[1;32m    773\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(data)\n\u001b[1;32m    775\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    776\u001b[0m     \u001b[39mif\u001b[39;00m is_dataclass(data[\u001b[39m0\u001b[39m]):\n",
      "Cell \u001b[0;32mIn[70], line 11\u001b[0m, in \u001b[0;36mcompute_similarities\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m node1 \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m: titles[i], \u001b[39m'\u001b[39m\u001b[39mabstract\u001b[39m\u001b[39m'\u001b[39m: abstracts[i], \u001b[39m'\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m'\u001b[39m: keywords[i] ,\u001b[39m'\u001b[39m\u001b[39mdomain\u001b[39m\u001b[39m'\u001b[39m: domains[i]}\n\u001b[1;32m     10\u001b[0m node2 \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m: titles[j], \u001b[39m'\u001b[39m\u001b[39mabstract\u001b[39m\u001b[39m'\u001b[39m: abstracts[j], \u001b[39m'\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m'\u001b[39m: keywords[j] ,\u001b[39m'\u001b[39m\u001b[39mdomain\u001b[39m\u001b[39m'\u001b[39m: domains[j]}\n\u001b[0;32m---> 11\u001b[0m t, a, k, d \u001b[39m=\u001b[39m compute_each_similarity(node1, node2)\n\u001b[1;32m     12\u001b[0m cache[key] \u001b[39m=\u001b[39m (t, a, k, d)\n\u001b[1;32m     13\u001b[0m \u001b[39myield\u001b[39;00m key, cache[key]\n",
      "Cell \u001b[0;32mIn[54], line 3\u001b[0m, in \u001b[0;36mcompute_each_similarity\u001b[0;34m(node1, node2)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_each_similarity\u001b[39m(node1, node2):\n\u001b[0;32m----> 3\u001b[0m     title_similarity \u001b[39m=\u001b[39m cosine_similarity([node1[\u001b[39m'\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m'\u001b[39;49m]], [node2[\u001b[39m'\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m'\u001b[39;49m]])[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m     abstract_similarity \u001b[39m=\u001b[39m cosine_similarity([node1[\u001b[39m'\u001b[39m\u001b[39mabstract\u001b[39m\u001b[39m'\u001b[39m]], [node2[\u001b[39m'\u001b[39m\u001b[39mabstract\u001b[39m\u001b[39m'\u001b[39m]])[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m     keyword_similarity \u001b[39m=\u001b[39m cosine_similarity([node1[\u001b[39m'\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m'\u001b[39m]], [node2[\u001b[39m'\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m'\u001b[39m]])[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:1577\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1543\u001b[0m \n\u001b[1;32m   1544\u001b[0m \u001b[39mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[39m    Returns the cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1575\u001b[0m \u001b[39m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1577\u001b[0m X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m   1579\u001b[0m X_normalized \u001b[39m=\u001b[39m normalize(X, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1580\u001b[0m \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:173\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    166\u001b[0m         X,\n\u001b[1;32m    167\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m     Y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    174\u001b[0m         Y,\n\u001b[1;32m    175\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    176\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    177\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    178\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    179\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m precomputed:\n\u001b[1;32m    183\u001b[0m     \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[1;32m    960\u001b[0m             array,\n\u001b[1;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    964\u001b[0m         )\n\u001b[1;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m# error message.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(over\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 120\u001b[0m     first_pass_isfinite \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39misfinite(xp\u001b[39m.\u001b[39;49msum(X))\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[1;32m   2314\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/.conda/envs/msc/lib/python3.10/site-packages/numpy/core/fromnumeric.py:71\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m         \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m         \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m         \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m---> 71\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapreduction\u001b[39m(obj, ufunc, method, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     72\u001b[0m     passkwargs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     73\u001b[0m                   \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue}\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(obj) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m mu\u001b[39m.\u001b[39mndarray:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cache = {}\n",
    "def compute_similarities():\n",
    "    for i in range(1000):\n",
    "        for j in range(i, 1000):\n",
    "            key = (i, j)\n",
    "            if key in cache:\n",
    "                yield key, cache[key]\n",
    "            else:\n",
    "                node1 = {'title': titles[i], 'abstract': abstracts[i], 'keywords': keywords[i] ,'domain': domains[i]}\n",
    "                node2 = {'title': titles[j], 'abstract': abstracts[j], 'keywords': keywords[j] ,'domain': domains[j]}\n",
    "                t, a, k, d = compute_each_similarity(node1, node2)\n",
    "                cache[key] = (t, a, k, d)\n",
    "                yield key, cache[key]\n",
    "similarities = compute_similarities()\n",
    "df = pd.DataFrame(similarities)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['titles'] = cosine_similarity(titles, titles)[0]\n",
    "df['domains'] = cosine_similarity(domains, domains)[0]\n",
    "df['keywords'] = cosine_similarity(keywords, keywords)[0]\n",
    "df['abstracts'] = cosine_similarity(abstracts, abstracts)[0]\n",
    "df.desciption()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[39m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.FloatTensor(titles)\n",
    "at = torch.FloatTensor(abstracts[:100])\n",
    "\n",
    "res = F.cosine_similarity(tt, tt, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tt = torch.FloatTensor(titles[:10000])\n",
    "res = F.cosine_similarity(tt.unsqueeze(0), tt.unsqueeze(1), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "res = cosine_similarity(titles, titles)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'citation_network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m n_nodes \u001b[39m=\u001b[39m citation_network\u001b[39m.\u001b[39mnumber_of_nodes()\n\u001b[1;32m      2\u001b[0m random_pair \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, n_nodes, (\u001b[39m100000\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[1;32m      4\u001b[0m src \u001b[39m=\u001b[39m random_pair[:, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'citation_network' is not defined"
     ]
    }
   ],
   "source": [
    "n_nodes = citation_network.number_of_nodes()\n",
    "random_pair = torch.randint(0, n_nodes, (100000, 2))\n",
    "\n",
    "src = random_pair[:, 0].numpy()\n",
    "dst = random_pair[:, 1].numpy()\n",
    "\n",
    "dfs = df.set_index(['src', 'dst'])\n",
    "random_pair_one = dfs[dfs.index.isin(list(zip(src, dst)))].reset_index().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(random_pair):\n",
    "    titles_similarity = cosine_similarity(titles[random_pair[:,0]], titles[random_pair[:,1]])\n",
    "    abstracts_similarity = cosine_similarity(abstracts[random_pair[:,0]], abstracts[random_pair[:,1]])\n",
    "    keywords_similarity = cosine_similarity(keywords[random_pair[:,0]], keywords[random_pair[:,1]])\n",
    "    domains_similarity = cosine_similarity(domains[random_pair[:,0]], domains[random_pair[:,1]])\n",
    "    \n",
    "    return titles_similarity, abstracts_similarity, keywords_similarity, domains_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = similarity_score(random_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
